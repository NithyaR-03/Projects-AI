{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3c03de9",
   "metadata": {},
   "source": [
    "####  Name: Nithya R\n",
    "####  Rol No  : 710020104310\n",
    "#### Assignment :3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bcf7c97",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Animal Classification Using CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2ef916",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b2cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a directory named .kaggle in the home directory\n",
    "os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9346713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Copy the kaggle.json file to the .kaggle directory in the home directory\n",
    "shutil.copyfile('kaggle.json', os.path.expanduser('~/.kaggle/kaggle.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c3f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d iamsouravbanerjee/animal-image-dataset-90-different-animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "650fabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Specify the path of the zip file\n",
    "zip_path = 'animal-image-dataset-90-different-animals.zip'\n",
    "\n",
    "# Specify the directory where you want to extract the files\n",
    "extract_path = 'animal-image-dataset-90-different-animals'\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    # Extract all the files to the specified directory\n",
    "    zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "917f01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bff38e0",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7613736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = \"animal-image-dataset-90-different-animals/animals/animals\"\n",
    "data = []\n",
    "class_name = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ad61118",
   "metadata": {},
   "source": [
    " #  Task 1: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0714f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [00:37<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for animal in tqdm(os.listdir(dataset_path)):\n",
    "    for i in range(len(os.listdir(dataset_path+ '/' + animal))):\n",
    "        if i < 40:\n",
    "            img = cv2.imread(dataset_path + '/' + animal + '/' + os.listdir(dataset_path+ '/' + animal)[i])\n",
    "            resized_img = cv2.resize(img,(224,224))\n",
    "            resized_img = resized_img / 255.0\n",
    "            data.append(resized_img)\n",
    "            class_name.append(animal)\n",
    "\n",
    "data = np.array(data,dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1321cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(class_name)\n",
    "class_names = le.classes_\n",
    "class_name = le.transform(class_name)\n",
    "\n",
    "class_name = np.array(class_name, dtype = 'uint8')\n",
    "class_name = np.resize(class_name, (len(class_name),1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3a5ec7f",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "798d8772",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6145b0e",
   "metadata": {},
   "source": [
    "##  Split the dataset into train and testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0857cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    data, class_name, test_size=0.3, stratify = class_name\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5452bc37",
   "metadata": {},
   "source": [
    "#  Task 2: Building CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d65ede56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library for Model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da72afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (224, 224, 3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67fc8300",
   "metadata": {},
   "source": [
    "# First I am using ----  Sequential model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d2370",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "# Create a list of all the class names\n",
    "class_name_list = os.listdir(dataset_path)\n",
    "\n",
    "# Create the training and testing directories\n",
    "os.mkdir(\"train\")\n",
    "os.mkdir(\"test\")\n",
    "\n",
    "# Move the images into their respective class folders\n",
    "for class_name in class_name_list:\n",
    "    os.mkdir(os.path.join(\"train\", class_name))\n",
    "    os.mkdir(os.path.join(\"test\", class_name))\n",
    "    images = os.listdir(os.path.join(dataset_path, class_name))\n",
    "    train_images, test_images = train_test_split(images, test_size=0.2)\n",
    "    for image in train_images:\n",
    "        src = os.path.join(dataset_path, class_name, image)\n",
    "        dst = os.path.join(\"train\", class_name, image)\n",
    "        shutil.copyfile(src, dst)\n",
    "    for image in test_images:\n",
    "        src = os.path.join(dataset_path, class_name, image)\n",
    "        dst = os.path.join(\"test\", class_name, image)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909323e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20616b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train\"\n",
    "\n",
    "# Create the training data generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "     shuffle=True,\n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the training dataset\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_path =\"test\"\n",
    "\n",
    "# Create the training data generator\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2616850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "model = Sequential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a396c989",
   "metadata": {},
   "source": [
    " ### 2a.     Input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "507e0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer\n",
    "model.add(Conv2D(224, (3, 3), activation=\"relu\", input_shape=input_shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08f392fe",
   "metadata": {},
   "source": [
    " ### 2b.    1 Convolution & 1 Pooling layer must to present task given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "600c55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dff833c",
   "metadata": {},
   "source": [
    "### 2c. 1 Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1777db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af5aa738",
   "metadata": {},
   "source": [
    "### 2d.  Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "22098f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first hidden layer\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "# second hidden layer\n",
    "model.add(Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8412a64",
   "metadata": {},
   "source": [
    "### 2e. Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30f005d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer\n",
    "model.add(Dense(90, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcf45e5a",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e9c5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e533e6d4",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "873019a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 14 00:00:16 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.41                 Driver Version: 531.41       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX450          WDDM | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   50C    P0               N/A /  N/A|      0MiB /  2048MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# checking before training the mode graphic card is ON or OFF\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "850b68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbf62187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "32/32 [==============================] - 368s 11s/step - loss: 4.6257 - accuracy: 0.0078\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 374s 12s/step - loss: 4.4971 - accuracy: 0.0117\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 403s 13s/step - loss: 4.5000 - accuracy: 0.0137\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 436s 14s/step - loss: 4.5003 - accuracy: 0.0088\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 437s 14s/step - loss: 4.5002 - accuracy: 0.0166\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 421s 13s/step - loss: 4.5000 - accuracy: 0.0146\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 404s 13s/step - loss: 4.5007 - accuracy: 0.0059\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 387s 12s/step - loss: 4.5009 - accuracy: 0.0078\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 388s 12s/step - loss: 4.5000 - accuracy: 0.0088\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 396s 12s/step - loss: 4.4994 - accuracy: 0.0127\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 375s 12s/step - loss: 4.4995 - accuracy: 0.0146\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 379s 12s/step - loss: 4.5002 - accuracy: 0.0127\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 397s 12s/step - loss: 4.4996 - accuracy: 0.0137\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 401s 13s/step - loss: 4.5003 - accuracy: 0.0127\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 362s 11s/step - loss: 4.4994 - accuracy: 0.0156\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 365s 11s/step - loss: 4.5008 - accuracy: 0.0088\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 364s 11s/step - loss: 4.5010 - accuracy: 0.0107\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 364s 11s/step - loss: 4.5005 - accuracy: 0.0107\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 365s 11s/step - loss: 4.5003 - accuracy: 0.0146\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 366s 11s/step - loss: 4.5004 - accuracy: 0.0137\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 365s 11s/step - loss: 4.5001 - accuracy: 0.0098\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 365s 11s/step - loss: 4.4996 - accuracy: 0.0098\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 366s 11s/step - loss: 4.5004 - accuracy: 0.0127\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 364s 11s/step - loss: 4.4994 - accuracy: 0.0146\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 365s 11s/step - loss: 4.4995 - accuracy: 0.0146\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 364s 11s/step - loss: 4.4999 - accuracy: 0.0107\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 364s 11s/step - loss: 4.4971 - accuracy: 0.0098\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 375s 12s/step - loss: 4.5013 - accuracy: 0.0049\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 366s 11s/step - loss: 4.5002 - accuracy: 0.0107\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 369s 12s/step - loss: 4.4997 - accuracy: 0.0127\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    steps_per_epoch=32,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=32\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "701016ab",
   "metadata": {},
   "source": [
    "## it's taken 3hours and 30 minute to complete 30 epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "677ff580",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "185b094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('animal_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d971ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9fdd0dd",
   "metadata": {},
   "source": [
    "# 3.Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e8db518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "77186cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model('animal_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "07fdefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image to test\n",
    "img = cv2.imread('eb30b9092cf7063ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88191f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img = Image.open('eb30b9092cf7063ed1584d05fb1d4e9fe777ead218ac104497f5c978a4efbcb0_640.jpg')\n",
    "\n",
    "# Resize the image to the same size used during training\n",
    "img = img.resize((224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "762cfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_array = np.array(img)\n",
    "\n",
    "# Reshape the array to have a batch dimension of 1\n",
    "img_array = img_array.reshape((1, 224, 224, 3))\n",
    "\n",
    "# Scale the pixel values to be between 0 and 1\n",
    "img_array = img_array / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68292fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n",
      "Result     fly\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get the index of the predicted class\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Invert the class_indices dictionary to get the actual class name\n",
    "class_indices = train_generator.class_indices\n",
    "class_names = {v: k for k, v in class_indices.items()}\n",
    "predicted_class_name = class_names[predicted_class_index]\n",
    "\n",
    "print('Result    ', predicted_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3a473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
